{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5s7qQ-DAKX1",
        "colab_type": "code",
        "outputId": "af894c2a-eff8-471c-bac3-dcb7cccb9c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQbiQPoFODt9",
        "colab_type": "code",
        "outputId": "be70baf1-48bc-4043-9977-8100cfe2f8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense,Flatten, LSTM,GRU, Conv1D,MaxPooling1D,Dropout,Activation,SpatialDropout1D,Bidirectional,BatchNormalization\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from sklearn import metrics\n",
        "import nltk\n",
        "import string\n",
        "import statistics\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_viquFxOH8z",
        "colab_type": "code",
        "outputId": "4026f143-6f14-4626-c807-a55aacc493f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "#Read training data\n",
        "path=\"/content/drive/My Drive/Toxic Project/train.csv\"\n",
        "train_data=pd.read_csv(path)\n",
        "train_data.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC4oCEh6OPcM",
        "colab_type": "code",
        "outputId": "1338e8f5-559f-44e0-d6b9-59a75f00f950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#check null values\n",
        "train_data.columns.isna()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZnUSzQwOSox",
        "colab_type": "code",
        "outputId": "b47cb375-6747-4159-cf1b-a7cfe9be404a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#extract y values\n",
        "y_train=np.array(train_data.drop(['id','comment_text'],axis=1))\n",
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxgUocomOXbB",
        "colab_type": "code",
        "outputId": "b7e30637-0abe-4385-c7b1-49becaab92bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "#read test data\n",
        "path_test=\"/content/drive/My Drive/Toxic Project/test.csv\"\n",
        "test_data=pd.read_csv(path_test)\n",
        "test_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>fffcd0960ee309b5</td>\n",
              "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>fffd7a9a6eb32c16</td>\n",
              "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>fffda9e8d6fafa9e</td>\n",
              "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>fffe8f1340a79fc2</td>\n",
              "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>ffffce3fb183ee80</td>\n",
              "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id                                       comment_text\n",
              "0       00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1       0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2       00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3       00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4       00017695ad8997eb          I don't anonymously edit articles at all.\n",
              "...                  ...                                                ...\n",
              "153159  fffcd0960ee309b5  . \\n i totally agree, this stuff is nothing bu...\n",
              "153160  fffd7a9a6eb32c16  == Throw from out field to home plate. == \\n\\n...\n",
              "153161  fffda9e8d6fafa9e  \" \\n\\n == Okinotorishima categories == \\n\\n I ...\n",
              "153162  fffe8f1340a79fc2  \" \\n\\n == \"\"One of the founding nations of the...\n",
              "153163  ffffce3fb183ee80  \" \\n :::Stop already. Your bullshit is not wel...\n",
              "\n",
              "[153164 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etrW9JleOb_A",
        "colab_type": "code",
        "outputId": "052003ed-5e05-4ac7-d3a4-f384e1244ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "#read test label\n",
        "test_label_path=\"/content/drive/My Drive/Toxic Project/test_labels.csv\"\n",
        "test_label=pd.read_csv(test_label_path)\n",
        "y_test=test_label.iloc[:,1:7]\n",
        "y_test[y_test==-1]=1\n",
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
              "0           1             1        1       1       1              1\n",
              "1           1             1        1       1       1              1\n",
              "2           1             1        1       1       1              1\n",
              "3           1             1        1       1       1              1\n",
              "4           1             1        1       1       1              1\n",
              "...       ...           ...      ...     ...     ...            ...\n",
              "153159      1             1        1       1       1              1\n",
              "153160      1             1        1       1       1              1\n",
              "153161      1             1        1       1       1              1\n",
              "153162      1             1        1       1       1              1\n",
              "153163      1             1        1       1       1              1\n",
              "\n",
              "[153164 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRE4Hrletqvd",
        "colab_type": "text"
      },
      "source": [
        "# **Pre-Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o_UogtMaNvg",
        "colab_type": "text"
      },
      "source": [
        "Remove stop words and stemmers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5FfH1owOlB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "def clean_text_sequence(x):\n",
        "    #clean punctuation \n",
        "    x=x.translate(string.punctuation)\n",
        "    \n",
        "    #convert text to lower case\n",
        "    x=x.lower()\n",
        "\n",
        "    #split the words\n",
        "    x=x.split()\n",
        "    \n",
        "    #remove stop words\n",
        "    remove_stopwords_list=set(stopwords.words(\"english\"))\n",
        "    \n",
        "    #select the threshold\n",
        "    new_word_list=[word for word in x if not word in  remove_stopwords_list and len(word)>3 ]\n",
        "\n",
        "            \n",
        "    text=\" \".join(new_word_list)\n",
        "    \n",
        "    #clean the text\n",
        "    #extracted by https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
        "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    #remove stemming i.e. overfitting>>>>overfit\n",
        "    \n",
        "    text_new=text.split()\n",
        "    stemmer_type=SnowballStemmer('english')\n",
        "    stemmed_words=[stemmer_type.stem(word) for word in text_new ]\n",
        "    \n",
        "\n",
        "        \n",
        "    text_stemmed=\" \".join(stemmed_words)\n",
        "    \n",
        "    return text_stemmed\n",
        "    \n",
        "            \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPIdEpfyPpec",
        "colab_type": "code",
        "outputId": "c14fa92b-85c5-4ecf-d721-6c2ab4c48a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hKrfMtSPszv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=train_data['comment_text'].map(lambda x:clean_text_sequence(x) )\n",
        "x_test=test_data['comment_text'].map(lambda x:clean_text_sequence(x) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzjws6AYaV2R",
        "colab_type": "text"
      },
      "source": [
        "Add impolite word list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TplJ1T13Pz6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unpolite_word_path=\"/content/drive/My Drive/Toxic Project/unpolite_word_list1.txt\"\n",
        "unpolite_words=pd.read_csv(unpolite_word_path,encoding='utf-8')\n",
        "unpolite_words_list=unpolite_words.iloc[:,0].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH2u2KklP3sg",
        "colab_type": "code",
        "outputId": "17c4a723-0bfb-4c54-d4d9-01afd16ef24a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt install -qq enchant\n",
        "!pip install pyenchant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 1,310 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 145674 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n",
            "Collecting pyenchant\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/54/04d88a59efa33fefb88133ceb638cdf754319030c28aadc5a379d82140ed/pyenchant-2.0.0.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyenchant\n",
            "  Building wheel for pyenchant (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyenchant: filename=pyenchant-2.0.0-cp36-none-any.whl size=71113 sha256=5b224ffa6090695e714b665018967cf4db41da7885faf45c1b17badd0f0d384b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/8e/01/f427e9c6c0ae5e22095f3d2aac8997abe7b317307a9de497f4\n",
            "Successfully built pyenchant\n",
            "Installing collected packages: pyenchant\n",
            "Successfully installed pyenchant-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Vf84C4a96q",
        "colab_type": "text"
      },
      "source": [
        "check and remove non English words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9OufRfRP6V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the x_train sequence is in English or not. Non English words are excluded\n",
        "import enchant\n",
        "new_x_train_list=[]\n",
        "dict = enchant.Dict(\"en_US\")\n",
        "\n",
        "for x in x_train:\n",
        "  temp_seq=\"\"\n",
        "  temp_word_list = x.split(\" \")\n",
        "  for y in range(len(temp_word_list)):\n",
        "    if not temp_word_list[y]:\n",
        "      continue\n",
        "    if temp_word_list[y] in unpolite_words_list:\n",
        "      temp_seq=temp_seq+temp_word_list[y] + \" \"\n",
        "    elif dict.check(temp_word_list[y]):\n",
        "      temp_seq=temp_seq+temp_word_list[y] + \" \"\n",
        "  new_x_train_list.append(temp_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6a1Bi01QBTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the x_test sequence is in English or not. Non English words are excluded\n",
        "import enchant\n",
        "new_x_test_list=[]\n",
        "dict = enchant.Dict(\"en_US\")\n",
        "\n",
        "for x in x_test:\n",
        "  temp_seq=\"\"\n",
        "  temp_word_list = x.split(\" \")\n",
        "  for y in range(len(temp_word_list)):\n",
        "    if not temp_word_list[y]:\n",
        "      continue\n",
        "    if temp_word_list[y] in unpolite_words_list:\n",
        "      temp_seq=temp_seq+temp_word_list[y] + \" \"\n",
        "    elif dict.check(temp_word_list[y]):\n",
        "      temp_seq=temp_seq+temp_word_list[y] + \" \"\n",
        "  new_x_test_list.append(temp_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClwKSWBzapda",
        "colab_type": "text"
      },
      "source": [
        "Tokenize the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfcfaQv8RTcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words=5000 #maximum number of words for embedding\n",
        "tokenizer=Tokenizer(num_words=unique_words)\n",
        "tokenizer.fit_on_texts(new_x_train_list)\n",
        "tokenizer.fit_on_texts(new_x_test_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFUFnLc1avFu",
        "colab_type": "text"
      },
      "source": [
        "Add tokens for the impolite word list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5Wxi9J8ahQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "size=len(unpolite_words_list)\n",
        "\n",
        "count=0\n",
        "word_list_temp=unpolite_words_list\n",
        "for w, index in word_index.items():\n",
        "    if w in unpolite_words_list:\n",
        "        word_list_temp.remove(w)\n",
        "        count+=1 \n",
        "    if index > (unique_words-size+count):\n",
        "        for u_w in word_list_temp:\n",
        "            tokenizer.word_index[u_w] = index\n",
        "            index+=1\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0EcsrRRRpt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_seq = tokenizer.texts_to_sequences(new_x_train_list)\n",
        "x_test_seq = tokenizer.texts_to_sequences(new_x_test_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxZRsv7ORqhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_size = len(tokenizer.word_index) + 1   \n",
        "max_length = 200 #maxmimum number of words for a sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XK9KUA_RtKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_pad = pad_sequences(x_train_seq, padding='post', maxlen=max_length)\n",
        "x_test_pad = pad_sequences(x_test_seq, padding='post', maxlen=max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bonOm1-RbEgE",
        "colab_type": "text"
      },
      "source": [
        "Add embedding glove to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2EqN6VxRy1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_glove=\"/content/drive/My Drive/Toxic Project/glove.6B.300d.txt\"\n",
        "embeddings_word_dict = {}\n",
        "with open(path_glove, 'r',encoding=\"utf8\") as file:\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_word_dict [word] = vector\n",
        "\n",
        "#match the embedding vector into the relavant word index\n",
        "embedding_word_vector = np.zeros((word_size, 300))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedd_vector = embeddings_word_dict .get(word)\n",
        "    if embedd_vector is not None:\n",
        "        embedding_word_vector [index] = embedd_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhFA-XcLR2O2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train1,x_val,y_train1,y_val=train_test_split(x_train_pad,y_train,random_state=123,test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX3puBUHt4s2",
        "colab_type": "text"
      },
      "source": [
        "# **Train the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS68jCuNbe83",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAsp1t2fR5l3",
        "colab_type": "code",
        "outputId": "e3a93e99-b0d2-4de9-c26a-af6c9744c813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model15 = Sequential()\n",
        "model15.add(Embedding(word_size, 300,weights=[embedding_word_vector], input_length=max_length))\n",
        "model15.add(SpatialDropout1D(0.2))\n",
        "model15.add(Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.2,activation='tanh',return_sequences=True)))\n",
        "# model14.add(Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.2,activation='tanh',return_sequences=True)))\n",
        "model15.add(Bidirectional(GRU((512), dropout=0.2, recurrent_dropout=0.2,activation='tanh',return_sequences=True)))\n",
        "model15.add(Bidirectional(GRU((512), dropout=0.2, recurrent_dropout=0.2,activation='tanh')))\n",
        "model15.add(Dense(64, activation='relu'))\n",
        "model15.add(Dense(64, activation='relu'))\n",
        "model15.add(Dense(6, activation='sigmoid'))\n",
        "model15.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model15.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 300)          8161800   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 200, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200, 512)          1140736   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 200, 1024)         3148800   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 1024)              4721664   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 17,243,150\n",
            "Trainable params: 17,243,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLZT37NdR8iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_checkpoint = ModelCheckpoint('/content/drive/My Drive/Toxic Project/model15_toxic_4.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
        "callback = EarlyStopping(monitor='val_loss',mode='min', verbose=1, patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYfAwrpwbmTN",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwUIC0UTl7pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import CSVLogger\n",
        "csv_logger = CSVLogger(\"/content/drive/My Drive/Toxic Project/model16_history_log.csv\", append=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4PVhJ0gk2DQ",
        "colab_type": "code",
        "outputId": "417bc377-a5c1-49e0-bc55-ab84075e7884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        }
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "model16=model15.fit(x_train1, y_train1, batch_size=512, epochs=10, verbose=2, validation_data=(x_val, y_val),\n",
        "         callbacks=[csv_logger,callback,model_checkpoint],class_weight = 'auto')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 106912 samples, validate on 52659 samples\n",
            "Epoch 1/10\n",
            " - 827s - loss: 0.0845 - acc: 0.9739 - val_loss: 0.0586 - val_acc: 0.9800\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.05858, saving model to /content/drive/My Drive/Toxic Project/model15_toxic_4.h5\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.05858 to 0.05613, saving model to /content/drive/My Drive/Toxic Project/model15_toxic_4.h5\n",
            "Epoch 3/10\n",
            " - 810s - loss: 0.0559 - acc: 0.9803 - val_loss: 0.0552 - val_acc: 0.9804\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.05613 to 0.05522, saving model to /content/drive/My Drive/Toxic Project/model15_toxic_4.h5\n",
            "Epoch 4/10\n",
            " - 810s - loss: 0.0534 - acc: 0.9810 - val_loss: 0.0539 - val_acc: 0.9810\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.05522 to 0.05390, saving model to /content/drive/My Drive/Toxic Project/model15_toxic_4.h5\n",
            "Epoch 5/10\n",
            " - 812s - loss: 0.0516 - acc: 0.9813 - val_loss: 0.0539 - val_acc: 0.9810\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.05390 to 0.05389, saving model to /content/drive/My Drive/Toxic Project/model15_toxic_4.h5\n",
            "Epoch 6/10\n",
            " - 811s - loss: 0.0500 - acc: 0.9817 - val_loss: 0.0542 - val_acc: 0.9811\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.05389\n",
            "Epoch 7/10\n",
            " - 811s - loss: 0.0482 - acc: 0.9822 - val_loss: 0.0544 - val_acc: 0.9808\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.05389\n",
            "Epoch 8/10\n",
            " - 809s - loss: 0.0464 - acc: 0.9827 - val_loss: 0.0552 - val_acc: 0.9813\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.05389\n",
            "Epoch 9/10\n",
            " - 810s - loss: 0.0447 - acc: 0.9832 - val_loss: 0.0573 - val_acc: 0.9811\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.05389\n",
            "Epoch 10/10\n",
            " - 810s - loss: 0.0430 - acc: 0.9838 - val_loss: 0.0570 - val_acc: 0.9809\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.05389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZWuuAy4S1ND",
        "colab_type": "text"
      },
      "source": [
        "Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwfpE5BMh_9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "new_model16=load_model(\"/content/drive/My Drive/Toxic Project/model15_toxic_4.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkaKWskcuGwa",
        "colab_type": "text"
      },
      "source": [
        "# **Test the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaNAYEo4buXm",
        "colab_type": "text"
      },
      "source": [
        "Predict validation and test values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl3z8_D1SQDp",
        "colab_type": "code",
        "outputId": "efcde72e-8614-4104-c86a-461e2371a4f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "predict_y_val15=new_model16.predict(x_val)\n",
        "predict_y_test15=new_model16.predict(x_test_pad)\n",
        "\n",
        "col_nammes=['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
        "y_validation_val=[]\n",
        "y_test_val=[]\n",
        "for i,col in enumerate(col_nammes):\n",
        "  roc_value_y_validation=metrics.roc_auc_score(y_val[:,i],predict_y_val15[:,i])\n",
        "  roc_value_y_test=metrics.roc_auc_score(y_test[col],predict_y_test15[:,i])\n",
        "\n",
        "  print(col,\"Validation_accuracy:\",roc_value_y_validation,\"\\t Test Accuracy:\",roc_value_y_test,\"\\n\")\n",
        "\n",
        "  y_validation_val.append(roc_value_y_validation)\n",
        "  y_test_val.append(roc_value_y_test)\n",
        "  \n",
        "Accuracy_y_validation=statistics.mean(y_validation_val)\n",
        "Accuracy_y_test=statistics.mean(y_test_val)\n",
        "print(\"Accuracy_y_validation\",Accuracy_y_validation)\n",
        "print(\"Accuracy_y_test\",Accuracy_y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic Validation_accuracy: 0.9617800020495831 \t Test Accuracy: 0.6343499624188337 \n",
            "\n",
            "severe_toxic Validation_accuracy: 0.9866084720569928 \t Test Accuracy: 0.5748018093303764 \n",
            "\n",
            "obscene Validation_accuracy: 0.9807510700600721 \t Test Accuracy: 0.6137221458149885 \n",
            "\n",
            "threat Validation_accuracy: 0.9714518144750702 \t Test Accuracy: 0.5684929702430188 \n",
            "\n",
            "insult Validation_accuracy: 0.9733421132309072 \t Test Accuracy: 0.6093530466290177 \n",
            "\n",
            "identity_hate Validation_accuracy: 0.9608818178880317 \t Test Accuracy: 0.5764716934024224 \n",
            "\n",
            "Accuracy_y_validation 0.9724692149601095\n",
            "Accuracy_y_test 0.5961986046397763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTpsHC5WRySL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OOswpZPR0MJ",
        "colab_type": "text"
      },
      "source": [
        "# **Sample Submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0jLiidccgWs",
        "colab_type": "code",
        "outputId": "8bf3f5ae-e47d-4bc2-e98f-14fcb1d8d1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predict_y_test15"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.98655319e-01, 3.93115282e-01, 9.60885763e-01, 1.61034822e-01,\n",
              "        9.06724215e-01, 3.22148889e-01],\n",
              "       [7.36292899e-02, 9.79125500e-04, 1.18361413e-02, 1.43319368e-03,\n",
              "        2.16493011e-02, 2.52637267e-03],\n",
              "       [1.07040286e-01, 2.16314197e-03, 1.72701180e-02, 1.55374408e-03,\n",
              "        3.99954021e-02, 8.19206238e-03],\n",
              "       ...,\n",
              "       [2.47502327e-03, 3.33786011e-06, 1.26153231e-04, 5.84125519e-06,\n",
              "        2.06917524e-04, 5.43296337e-05],\n",
              "       [1.20481849e-03, 1.69873238e-06, 7.18832016e-05, 2.47359276e-06,\n",
              "        1.25497580e-04, 2.98023224e-05],\n",
              "       [9.80882108e-01, 4.26388681e-02, 8.51195812e-01, 1.29240751e-02,\n",
              "        5.42769492e-01, 2.69401968e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSk6b-nMci1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame(predict_y_test15,columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjYorohgM02U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.insert(loc=0, column='id', value=test_data['id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02hoA9A7NCy4",
        "colab_type": "code",
        "outputId": "efc0e1a9-f5b3-4212-f58e-904819206aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.998655</td>\n",
              "      <td>0.393115</td>\n",
              "      <td>0.960886</td>\n",
              "      <td>0.161035</td>\n",
              "      <td>0.906724</td>\n",
              "      <td>0.322149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.073629</td>\n",
              "      <td>0.000979</td>\n",
              "      <td>0.011836</td>\n",
              "      <td>0.001433</td>\n",
              "      <td>0.021649</td>\n",
              "      <td>0.002526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.107040</td>\n",
              "      <td>0.002163</td>\n",
              "      <td>0.017270</td>\n",
              "      <td>0.001554</td>\n",
              "      <td>0.039995</td>\n",
              "      <td>0.008192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.001769</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.000039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.028739</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.005229</td>\n",
              "      <td>0.000908</td>\n",
              "      <td>0.006142</td>\n",
              "      <td>0.000672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>fffcd0960ee309b5</td>\n",
              "      <td>0.731470</td>\n",
              "      <td>0.004589</td>\n",
              "      <td>0.345150</td>\n",
              "      <td>0.002379</td>\n",
              "      <td>0.136114</td>\n",
              "      <td>0.011209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>fffd7a9a6eb32c16</td>\n",
              "      <td>0.004947</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000437</td>\n",
              "      <td>0.000089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>fffda9e8d6fafa9e</td>\n",
              "      <td>0.002475</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000207</td>\n",
              "      <td>0.000054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>fffe8f1340a79fc2</td>\n",
              "      <td>0.001205</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>ffffce3fb183ee80</td>\n",
              "      <td>0.980882</td>\n",
              "      <td>0.042639</td>\n",
              "      <td>0.851196</td>\n",
              "      <td>0.012924</td>\n",
              "      <td>0.542769</td>\n",
              "      <td>0.026940</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id     toxic  ...    insult  identity_hate\n",
              "0       00001cee341fdb12  0.998655  ...  0.906724       0.322149\n",
              "1       0000247867823ef7  0.073629  ...  0.021649       0.002526\n",
              "2       00013b17ad220c46  0.107040  ...  0.039995       0.008192\n",
              "3       00017563c3f7919a  0.001769  ...  0.000193       0.000039\n",
              "4       00017695ad8997eb  0.028739  ...  0.006142       0.000672\n",
              "...                  ...       ...  ...       ...            ...\n",
              "153159  fffcd0960ee309b5  0.731470  ...  0.136114       0.011209\n",
              "153160  fffd7a9a6eb32c16  0.004947  ...  0.000437       0.000089\n",
              "153161  fffda9e8d6fafa9e  0.002475  ...  0.000207       0.000054\n",
              "153162  fffe8f1340a79fc2  0.001205  ...  0.000125       0.000030\n",
              "153163  ffffce3fb183ee80  0.980882  ...  0.542769       0.026940\n",
              "\n",
              "[153164 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb8ujT4nL763",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"/content/drive/My Drive/Toxic Project/results2_model15.csv\", index=True, sep=\";\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aGsHkCIR7VL",
        "colab_type": "text"
      },
      "source": [
        "# **Plot - Validation loss vs Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAjQQNs_cuvu",
        "colab_type": "code",
        "outputId": "4d4db87b-87cd-4e7e-ce7e-aa361c559f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "plt.suptitle('Optimizer-Adam', fontsize=10)\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.legend(loc='upper right')\n",
        "plt.plot(model16.history['loss'], color='b', label='Training Loss')\n",
        "plt.plot(model16.history['val_loss'], color='r', label='Validation Loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9b0744f400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEnCAYAAABVIB9ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}