{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7c7ildadADB",
        "colab_type": "code",
        "outputId": "4e4851e2-c7d7-4436-f4c9-987a6d963e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98bAGErS0kG6",
        "colab_type": "code",
        "outputId": "43195196-2332-4310-9a28-1707798456bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense,Flatten, LSTM, Conv1D,MaxPooling1D,Dropout,Activation,SpatialDropout1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn import metrics\n",
        "import nltk\n",
        "import string\n",
        "import statistics\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPcqxQ-cHg4s",
        "colab_type": "code",
        "outputId": "2c3e6c83-062d-4268-b6ff-db2c50dff91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "path=\"/content/drive/My Drive/Toxic Project/train.csv\"\n",
        "train_data=pd.read_csv(path)\n",
        "train_data.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6oZlgKqHmwQ",
        "colab_type": "code",
        "outputId": "b9eb5389-1f63-4344-d5d2-7d7ad2022652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_data.columns.isna()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJFyQ8G7IDWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backup = pd.HDFStore('backup_toxic_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXOSEdAVIILM",
        "colab_type": "code",
        "outputId": "17d42684-bebf-4297-b837-674b4009dd52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "y_train=np.array(train_data.drop(['id','comment_text'],axis=1))\n",
        "y_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxqqyrjmILUz",
        "colab_type": "code",
        "outputId": "ff553729-f617-4853-84b1-7c2d029bbab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "path_test=\"/content/drive/My Drive/Toxic Project/test.csv\"\n",
        "test_data=pd.read_csv(path_test)\n",
        "test_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>fffcd0960ee309b5</td>\n",
              "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>fffd7a9a6eb32c16</td>\n",
              "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>fffda9e8d6fafa9e</td>\n",
              "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>fffe8f1340a79fc2</td>\n",
              "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>ffffce3fb183ee80</td>\n",
              "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id                                       comment_text\n",
              "0       00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1       0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2       00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3       00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4       00017695ad8997eb          I don't anonymously edit articles at all.\n",
              "...                  ...                                                ...\n",
              "153159  fffcd0960ee309b5  . \\n i totally agree, this stuff is nothing bu...\n",
              "153160  fffd7a9a6eb32c16  == Throw from out field to home plate. == \\n\\n...\n",
              "153161  fffda9e8d6fafa9e  \" \\n\\n == Okinotorishima categories == \\n\\n I ...\n",
              "153162  fffe8f1340a79fc2  \" \\n\\n == \"\"One of the founding nations of the...\n",
              "153163  ffffce3fb183ee80  \" \\n :::Stop already. Your bullshit is not wel...\n",
              "\n",
              "[153164 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gpn8mlHIT4F",
        "colab_type": "code",
        "outputId": "41398f27-b26f-43be-fdbb-6c7eab517e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "test_label_path=\"/content/drive/My Drive/Toxic Project/test_labels.csv\"\n",
        "test_label=pd.read_csv(test_label_path)\n",
        "y_test=test_label.iloc[:,1:7]\n",
        "y_test[y_test==-1]=1\n",
        "y_test"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153159</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153160</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153161</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153162</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153163</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153164 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
              "0           1             1        1       1       1              1\n",
              "1           1             1        1       1       1              1\n",
              "2           1             1        1       1       1              1\n",
              "3           1             1        1       1       1              1\n",
              "4           1             1        1       1       1              1\n",
              "...       ...           ...      ...     ...     ...            ...\n",
              "153159      1             1        1       1       1              1\n",
              "153160      1             1        1       1       1              1\n",
              "153161      1             1        1       1       1              1\n",
              "153162      1             1        1       1       1              1\n",
              "153163      1             1        1       1       1              1\n",
              "\n",
              "[153164 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot2zPLGGIeCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "def clean_text_sequence(x):\n",
        "    #clean punctuation \n",
        "    x=x.translate(string.punctuation)\n",
        "    \n",
        "    #convert text to lower case\n",
        "    x=x.lower()\n",
        "\n",
        "    #split the words\n",
        "    x=x.split()\n",
        "    \n",
        "    #remove stop words\n",
        "    remove_stopwords_list=set(stopwords.words(\"english\"))\n",
        "    \n",
        "    #select the threshold\n",
        "    new_word_list=[word for word in x if not word in  remove_stopwords_list and len(word)>3 ]\n",
        "\n",
        "            \n",
        "    text=\" \".join(new_word_list)\n",
        "    \n",
        "    #clean the text\n",
        "    #extracted by https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
        "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    #remove stemming i.e. overfitting>>>>overfit\n",
        "    \n",
        "    text_new=text.split()\n",
        "    stemmer_type=SnowballStemmer('english')\n",
        "    stemmed_words=[stemmer_type.stem(word) for word in text_new ]\n",
        "    \n",
        "#     for word in text_new:\n",
        "#         stemmed_words=[]\n",
        "#         stemmed_words.append(stemmer_type.stem(word))\n",
        "        \n",
        "    text_stemmed=\" \".join(stemmed_words)\n",
        "    \n",
        "    return text_stemmed\n",
        "    \n",
        "            \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhfwCtDcIiei",
        "colab_type": "code",
        "outputId": "5266380e-04a2-4921-f044-7312978c61ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQLwLZ_pIx_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=train_data['comment_text'].map(lambda x:clean_text_sequence(x) )\n",
        "x_test=test_data['comment_text'].map(lambda x:clean_text_sequence(x) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63eFdWfXKH4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words=5000 #maximum number of words for embedding\n",
        "tokenizer=Tokenizer(num_words=unique_words)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "tokenizer.fit_on_texts(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8UpFHm4KVIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
        "x_test_seq = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7wvJa0PKc6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_size = len(tokenizer.word_index) + 1   \n",
        "max_length = 200 #maxmimum number of words for a sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EssUeHcZKf9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_pad = pad_sequences(x_train_seq, padding='post', maxlen=max_length)\n",
        "x_test_pad = pad_sequences(x_test_seq, padding='post', maxlen=max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enVPXKT1LFwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_glove=\"/content/drive/My Drive/Toxic Project/glove.6B.300d.txt\"\n",
        "embeddings_dict = {}\n",
        "with open(path_glove, 'r',encoding=\"utf8\") as file:\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector\n",
        "\n",
        "#match the embedding vector into the relavant word index\n",
        "embedding_word_vector = np.zeros((word_size, 300))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedd_vector = embeddings_dict.get(word)\n",
        "    if embedd_vector is not None:\n",
        "        embedding_word_vector [index] = embedd_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB-RBoMmOHMz",
        "colab_type": "code",
        "outputId": "f408552a-d021-42ea-ec29-071eb0220e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train_pad.shape[1]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VESr9k0eF4yQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embedd_dim=300\n",
        "# size_of_filter=[3,4]\n",
        "# no_filters=100\n",
        "\n",
        "# input=Input(shape=(x_train_pad.shape[1],))\n",
        "# embedding_layer=Embedding(vocab_size,Embedd_dim,weights=[embedding_word_vector],trainable=True)(input)\n",
        "# reshape_embedding=Reshape((x_train_pad.shape[1],Embedd_dim,1))(embedding_layer)\n",
        "# conv_layer1 = Conv2D(no_filters, (size_of_filter.shape[0], Embedd_dim),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape_embedding)\n",
        "# conv_layer2 = Conv2D(no_filters, (size_of_filter.shape[1], Embedd_dim),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape_embedding)\n",
        "# maxpool_0 = MaxPooling2D((x_train_pad.shape[1]- size_of_filter.shape[0] + 1, 1), strides=(1,1))(conv_layer1)\n",
        "# maxpool_1 = MaxPooling2D((sequence_length - filter_sizes[1] + 1, 1), strides=(1,1))(conv_1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC0P5Sb1Xr68",
        "colab_type": "code",
        "outputId": "774b21da-0073-4240-9489-e216ccb5de5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "embed_inputs = Input(shape=(max_length,))\n",
        "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_word_vector], trainable=False)(embed_inputs)\n",
        "LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
        "dense_layer_1 = Dense(6, activation='sigmoid')(LSTM_Layer_1)\n",
        "model1 = Model(inputs=embed_inputs, outputs=dense_layer_1)\n",
        "\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 200, 300)          77519400  \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               219648    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 77,739,822\n",
            "Trainable params: 220,422\n",
            "Non-trainable params: 77,519,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Idjc1AYUqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train1,x_val,y_train1,y_val=train_test_split(x_train_pad,y_train,random_state=42,test_size=0.33)\n",
        "callbacks = [EarlyStopping(monitor='val_loss')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkrutCW5YlkE",
        "colab_type": "code",
        "outputId": "9ce350ae-ee9f-4e25-d57b-0c7a509f257f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "model1.fit(x_train1, y_train1, batch_size=400, epochs=10, verbose=2, validation_data=(x_val, y_val),\n",
        "         callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 106912 samples, validate on 52659 samples\n",
            "Epoch 1/10\n",
            " - 756s - loss: 0.1638 - acc: 0.9618 - val_loss: 0.1398 - val_acc: 0.9630\n",
            "Epoch 2/10\n",
            " - 745s - loss: 0.1398 - acc: 0.9637 - val_loss: 0.1413 - val_acc: 0.9631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f72c25d7208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f36GPUT6ZD3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.save(\"model1_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtV100g5ZW0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "new_model=load_model(\"model1_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvqFHwz2e_CI",
        "colab_type": "code",
        "outputId": "43669880-7f60-4f86-afaf-a2c108327ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model1.evaluate(x_val, y_val,batch_size=400, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52659/52659 [==============================] - 115s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14131923881656963, 0.9630768952910013]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnq8jCucZaNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_val=model1.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRVtdNiUZmNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_test=model1.predict(x_test_pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNL0icxZt3C",
        "colab_type": "code",
        "outputId": "4a9ed61f-7b02-44d0-f1a9-dad3c30d9392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "col_nammes=['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
        "y_validation_val=[]\n",
        "y_test_val=[]\n",
        "for i,col in enumerate(col_nammes):\n",
        "  roc_value_y_validation=metrics.roc_auc_score(y_val[:,i],predict_y_val[:,i])\n",
        "  roc_value_y_test=metrics.roc_auc_score(y_test[col],predict_y_test[:,i])\n",
        "  print(col,\"Validation_accuracy:\",roc_value_y_validation,\"\\t Test Accuracy:\",roc_value_y_test,\"\\n\")\n",
        "  y_validation_val.append(roc_value_y_validation)\n",
        "  y_test_val.append(roc_value_y_test)\n",
        "Accuracy_y_validation=statistics.mean(y_validation_val)\n",
        "Accuracy_y_test=statistics.mean(y_test_val)\n",
        "print(\"Accuracy_y_validation\",Accuracy_y_validation)\n",
        "print(\"Accuracy_y_test\",Accuracy_y_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic Validation_accuracy: 0.5511206795511311 \t Test Accuracy: 0.5219676795936213 \n",
            "\n",
            "severe_toxic Validation_accuracy: 0.5460698503002595 \t Test Accuracy: 0.5065598618301134 \n",
            "\n",
            "obscene Validation_accuracy: 0.5365650667685747 \t Test Accuracy: 0.5132172545126181 \n",
            "\n",
            "threat Validation_accuracy: 0.497574070324458 \t Test Accuracy: 0.5071377938234055 \n",
            "\n",
            "insult Validation_accuracy: 0.4858373924203506 \t Test Accuracy: 0.4920984477233238 \n",
            "\n",
            "identity_hate Validation_accuracy: 0.5093126280178943 \t Test Accuracy: 0.5013044920669169 \n",
            "\n",
            "Accuracy_y_validation 0.5210799478971113\n",
            "Accuracy_y_test 0.5070475882583332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42LGqqzUkuO9",
        "colab_type": "code",
        "outputId": "d5dba5e1-38dd-4b3d-9d0d-24e706745064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "model2=Sequential()\n",
        "seq_length=x_test_pad.shape[1]\n",
        "model2.add(Embedding(5000, 300, input_length=seq_length))\n",
        "model2.add(LSTM(256))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 300)          1500000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256)               570368    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 2,087,206\n",
            "Trainable params: 2,087,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot8q7ALcl9uk",
        "colab_type": "code",
        "outputId": "1efac81b-3386-4aae-8d9b-efac79d82693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "model2.fit(x_train1, y_train1, batch_size=400, epochs=10, verbose=2, validation_data=(x_val, y_val),\n",
        "         callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 106912 samples, validate on 52659 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 104s - loss: 0.1468 - acc: 0.9627 - val_loss: 0.1311 - val_acc: 0.9661\n",
            "Epoch 2/10\n",
            " - 96s - loss: 0.1259 - acc: 0.9679 - val_loss: 0.1419 - val_acc: 0.9631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e06a560b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jun898PmH4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save(\"model2_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB30RoN1mL4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "new_model2=load_model(\"model2_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQCrc9I8mVVD",
        "colab_type": "code",
        "outputId": "c6bb5f95-793a-4d56-aae1-514df0669720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "new_model2.evaluate(x_val, y_val,batch_size=400, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52659/52659 [==============================] - 15s 281us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14190997605888925, 0.9631401992065577]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NHwUsLkmXB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_val2=new_model2.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N44Eog0Xmd_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_test2=new_model2.predict(x_test_pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB32q0WsmoaE",
        "colab_type": "code",
        "outputId": "0e781b49-8899-4906-e16a-a3348d2f15d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "col_nammes=['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
        "y_validation_val=[]\n",
        "y_test_val=[]\n",
        "for i,col in enumerate(col_nammes):\n",
        "  roc_value_y_validation=metrics.roc_auc_score(y_val[:,i],predict_y_val2[:,i])\n",
        "  roc_value_y_test=metrics.roc_auc_score(y_test[col],predict_y_test2[:,i])\n",
        "\n",
        "  print(col,\"Validation_accuracy:\",roc_value_y_validation,\"\\t Test Accuracy:\",roc_value_y_test,\"\\n\")\n",
        "\n",
        "  y_validation_val.append(roc_value_y_validation)\n",
        "  y_test_val.append(roc_value_y_test)\n",
        "  \n",
        "Accuracy_y_validation=statistics.mean(y_validation_val)\n",
        "Accuracy_y_test=statistics.mean(y_test_val)\n",
        "print(\"Accuracy_y_validation\",Accuracy_y_validation)\n",
        "print(\"Accuracy_y_test\",Accuracy_y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic Validation_accuracy: 0.5192036839548082 \t Test Accuracy: 0.5063329637776801 \n",
            "\n",
            "severe_toxic Validation_accuracy: 0.5249563506734273 \t Test Accuracy: 0.49939788987057326 \n",
            "\n",
            "obscene Validation_accuracy: 0.5016465826476991 \t Test Accuracy: 0.49927641810873447 \n",
            "\n",
            "threat Validation_accuracy: 0.548220826195605 \t Test Accuracy: 0.50621943851948 \n",
            "\n",
            "insult Validation_accuracy: 0.5023140381683991 \t Test Accuracy: 0.4999507444061633 \n",
            "\n",
            "identity_hate Validation_accuracy: 0.507104723621296 \t Test Accuracy: 0.499331793973647 \n",
            "\n",
            "Accuracy_y_validation 0.5172410342102058\n",
            "Accuracy_y_test 0.5017515414427131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8sDNeFLMAKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unpolite_word_path=\"/content/drive/My Drive/Toxic Project/unpolite_word_list.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XQR2FCIOoWh",
        "colab_type": "code",
        "outputId": "0dfb32d0-639b-463e-a5fa-c6e4db2c61f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "unpolite_words=pd.read_csv(unpolite_word_path,header=None)\n",
        "print(unpolite_words)\n",
        "unpolite_words_list=unpolite_words.iloc[:,0].tolist()\n",
        "type(unpolite_words_list)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           0\n",
            "0       4r5e\n",
            "1       5h1t\n",
            "2       5hit\n",
            "3        a55\n",
            "4       anal\n",
            "..       ...\n",
            "446    whore\n",
            "447  willies\n",
            "448    willy\n",
            "449   xrated\n",
            "450      xxx\n",
            "\n",
            "[451 rows x 1 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J35k95MbTMrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THndCCmaQELr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size=len(unpolite_words_list)\n",
        "count=0\n",
        "word_list_temp=unpolite_words_list\n",
        "for w, index in word_index.items():\n",
        "    if w in unpolite_words_list:\n",
        "        word_list_temp.remove(w)\n",
        "        count+=1 \n",
        "    if index > (unique_words-size+count):\n",
        "        for u_w in word_list_temp:\n",
        "            tokenizer.word_index[u_w] = index\n",
        "            index+=1\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiObV1iHcf8L",
        "colab_type": "code",
        "outputId": "72eed761-3bf9-44e5-843f-49e6b2c26f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "model3=Sequential()\n",
        "seq_length=x_test_pad.shape[1]\n",
        "model3.add(Embedding(5000, 300, input_length=seq_length))\n",
        "model3.add(LSTM(256))\n",
        "model3.add(Dense(64, activation='relu'))\n",
        "model3.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 200, 300)          1500000   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               570368    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 2,087,206\n",
            "Trainable params: 2,087,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io_foXzMc8_Y",
        "colab_type": "code",
        "outputId": "dc3d35bf-91c6-4983-f580-e0dda2107a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model3.fit(x_train1, y_train1, batch_size=400, epochs=10, verbose=2, validation_data=(x_val, y_val),\n",
        "         callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 106912 samples, validate on 52659 samples\n",
            "Epoch 1/10\n",
            " - 99s - loss: 0.1499 - acc: 0.9617 - val_loss: 0.1320 - val_acc: 0.9661\n",
            "Epoch 2/10\n",
            " - 98s - loss: 0.1254 - acc: 0.9679 - val_loss: 0.1240 - val_acc: 0.9680\n",
            "Epoch 3/10\n",
            " - 97s - loss: 0.1193 - acc: 0.9691 - val_loss: 0.1217 - val_acc: 0.9678\n",
            "Epoch 4/10\n",
            " - 97s - loss: 0.1178 - acc: 0.9677 - val_loss: 0.1193 - val_acc: 0.9677\n",
            "Epoch 5/10\n",
            " - 97s - loss: 0.1185 - acc: 0.9676 - val_loss: 0.1414 - val_acc: 0.9632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d064db4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OURrZfH8dJHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.save(\"model3_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD0nkeLwdQUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "new_model3=load_model(\"model3_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfLno_L-dU0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_val3=new_model3.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ44j_HkdUyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_test3=new_model3.predict(x_test_pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnBBwtmnddj3",
        "colab_type": "code",
        "outputId": "41bb7540-b336-48e2-f536-55134ef782b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "col_nammes=['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
        "y_validation_val=[]\n",
        "y_test_val=[]\n",
        "for i,col in enumerate(col_nammes):\n",
        "  roc_value_y_validation=metrics.roc_auc_score(y_val[:,i],predict_y_val3[:,i])\n",
        "  roc_value_y_test=metrics.roc_auc_score(y_test[col],predict_y_test3[:,i])\n",
        "\n",
        "  print(col,\"Validation_accuracy:\",roc_value_y_validation,\"\\t Test Accuracy:\",roc_value_y_test,\"\\n\")\n",
        "\n",
        "  y_validation_val.append(roc_value_y_validation)\n",
        "  y_test_val.append(roc_value_y_test)\n",
        "  \n",
        "Accuracy_y_validation=statistics.mean(y_validation_val)\n",
        "Accuracy_y_test=statistics.mean(y_test_val)\n",
        "print(\"Accuracy_y_validation\",Accuracy_y_validation)\n",
        "print(\"Accuracy_y_test\",Accuracy_y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic Validation_accuracy: 0.5051185630456401 \t Test Accuracy: 0.5019792036870694 \n",
            "\n",
            "severe_toxic Validation_accuracy: 0.5193526115093604 \t Test Accuracy: 0.5018964895143468 \n",
            "\n",
            "obscene Validation_accuracy: 0.5091703627203117 \t Test Accuracy: 0.5026534508744861 \n",
            "\n",
            "threat Validation_accuracy: 0.5065386018706277 \t Test Accuracy: 0.5006627658053762 \n",
            "\n",
            "insult Validation_accuracy: 0.5080016770721149 \t Test Accuracy: 0.5025903071990497 \n",
            "\n",
            "identity_hate Validation_accuracy: 0.5117132661159547 \t Test Accuracy: 0.5015848283625435 \n",
            "\n",
            "Accuracy_y_validation 0.5099825137223349\n",
            "Accuracy_y_test 0.5018945075738119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2mak1jpsZjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "cb42b0bd-5668-4854-ba40-4ed784ed13c9"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "embed_inputs = Input(shape=(max_length,))\n",
        "embedding_layer = Embedding(word_size, 300, weights=[embedding_word_vector], trainable=False)(embed_inputs)\n",
        "LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
        "dense_layer_1 = Dense(6, activation='sigmoid')(LSTM_Layer_1)\n",
        "model4 = Model(inputs=embed_inputs, outputs=dense_layer_1)\n",
        "\n",
        "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model4.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 200, 300)          77519400  \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 128)               219648    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 77,739,822\n",
            "Trainable params: 220,422\n",
            "Non-trainable params: 77,519,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLKXrY1ItNvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a53acc07-d6de-430a-842f-b66932f04231"
      },
      "source": [
        "model4.fit(x_train1, y_train1, batch_size=400, epochs=10, verbose=2, validation_data=(x_val, y_val),\n",
        "         callbacks=callbacks)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 106912 samples, validate on 52659 samples\n",
            "Epoch 1/10\n",
            " - 82s - loss: 0.1662 - acc: 0.9628 - val_loss: 0.1422 - val_acc: 0.9625\n",
            "Epoch 2/10\n",
            " - 81s - loss: 0.1398 - acc: 0.9636 - val_loss: 0.1420 - val_acc: 0.9632\n",
            "Epoch 3/10\n",
            " - 81s - loss: 0.1388 - acc: 0.9639 - val_loss: 0.1268 - val_acc: 0.9632\n",
            "Epoch 4/10\n",
            " - 80s - loss: 0.0846 - acc: 0.9730 - val_loss: 0.0724 - val_acc: 0.9761\n",
            "Epoch 5/10\n",
            " - 81s - loss: 0.0652 - acc: 0.9785 - val_loss: 0.0638 - val_acc: 0.9789\n",
            "Epoch 6/10\n",
            " - 80s - loss: 0.0610 - acc: 0.9795 - val_loss: 0.0641 - val_acc: 0.9790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff5b534dc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiahO4vju1ZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4.save(\"model4_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRtNhqr1sZg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "new_model4=load_model(\"model4_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taFZ07hYvJa2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ee4578fb-8392-4621-f293-80b76d5387b7"
      },
      "source": [
        "new_model4.evaluate(x_val, y_val,batch_size=400, verbose=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52659/52659 [==============================] - 15s 280us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06408151398004533, 0.9789652835494461]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRoFtTEbvOpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_val4=new_model4.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NP2j3cUvUVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_test4=new_model4.predict(x_test_pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBRwIzkRvcSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "1bcaa90d-1da4-498e-ecad-7cb6508a26a8"
      },
      "source": [
        "col_nammes=['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
        "y_validation_val=[]\n",
        "y_test_val=[]\n",
        "for i,col in enumerate(col_nammes):\n",
        "  roc_value_y_validation=metrics.roc_auc_score(y_val[:,i],predict_y_val4[:,i])\n",
        "  roc_value_y_test=metrics.roc_auc_score(y_test[col],predict_y_test4[:,i])\n",
        "\n",
        "  print(col,\"Validation_accuracy:\",roc_value_y_validation,\"\\t Test Accuracy:\",roc_value_y_test,\"\\n\")\n",
        "\n",
        "  y_validation_val.append(roc_value_y_validation)\n",
        "  y_test_val.append(roc_value_y_test)\n",
        "  \n",
        "Accuracy_y_validation=statistics.mean(y_validation_val)\n",
        "Accuracy_y_test=statistics.mean(y_test_val)\n",
        "print(\"Accuracy_y_validation\",Accuracy_y_validation)\n",
        "print(\"Accuracy_y_test\",Accuracy_y_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic Validation_accuracy: 0.9461138434755879 \t Test Accuracy: 0.633812034192025 \n",
            "\n",
            "severe_toxic Validation_accuracy: 0.9801541888438454 \t Test Accuracy: 0.5755646999416963 \n",
            "\n",
            "obscene Validation_accuracy: 0.9713371397820441 \t Test Accuracy: 0.6125020380961956 \n",
            "\n",
            "threat Validation_accuracy: 0.93934048141952 \t Test Accuracy: 0.5732022764133855 \n",
            "\n",
            "insult Validation_accuracy: 0.9626572731686134 \t Test Accuracy: 0.6084693344116923 \n",
            "\n",
            "identity_hate Validation_accuracy: 0.9412532015152796 \t Test Accuracy: 0.5785069185851174 \n",
            "\n",
            "Accuracy_y_validation 0.9568093547008151\n",
            "Accuracy_y_test 0.597009550273352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxZcfd7Z9Pyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "aba306be-b23b-4344-8b85-6da7598c2ddc"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "embed_inputs = Input(shape=(max_length,))\n",
        "embedding_layer = Embedding(word_size, 300, weights=[embedding_word_vector], trainable=False)(embed_inputs)\n",
        "LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
        "dense_layer_1 = Dense(64, activation='relu')(LSTM_Layer_1)\n",
        "dense_layer_2 = Dense(6, activation='sigmoid')(dense_layer_1)\n",
        "model5 = Model(inputs=embed_inputs, outputs=dense_layer_2)\n",
        "\n",
        "model5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model5.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_9 (Embedding)      (None, 200, 300)          77519400  \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 128)               219648    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 77,747,694\n",
            "Trainable params: 228,294\n",
            "Non-trainable params: 77,519,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HqDSRXz9ioi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "6849c810-0f16-4c63-a367-d49d1011164d"
      },
      "source": [
        "model5.fit(x_train1, y_train1, batch_size=400, epochs=10, verbose=2, validation_data=(x_val, y_val),\n",
        "         callbacks=callbacks)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 106912 samples, validate on 52659 samples\n",
            "Epoch 1/10\n",
            " - 82s - loss: 0.1380 - acc: 0.9635 - val_loss: 0.1356 - val_acc: 0.9639\n",
            "Epoch 2/10\n",
            " - 82s - loss: 0.1230 - acc: 0.9658 - val_loss: 0.1141 - val_acc: 0.9640\n",
            "Epoch 3/10\n",
            " - 82s - loss: 0.1090 - acc: 0.9649 - val_loss: 0.1100 - val_acc: 0.9628\n",
            "Epoch 4/10\n",
            " - 82s - loss: 0.1118 - acc: 0.9637 - val_loss: 0.1145 - val_acc: 0.9631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff5b46ad898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_mO4mOkIX-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model5.save(\"model5_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEzG9M5lIdJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "new_model5=load_model(\"model5_toxic_2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Q7yYDjIwAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "920dec37-34b0-47f5-a036-34f9b535cbce"
      },
      "source": [
        "new_model5.evaluate(x_val, y_val,batch_size=400, verbose=1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52659/52659 [==============================] - 15s 277us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11448255457241126, 0.9631496944769595]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1t-EFE4I1nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_val5=new_model5.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMfBZCy-I9p2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_y_test5=new_model5.predict(x_test_pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZzGRQbPJGu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "6a38ed9e-f5c0-475e-cb5f-a8bf295f916e"
      },
      "source": [
        "col_nammes=['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
        "y_validation_val=[]\n",
        "y_test_val=[]\n",
        "for i,col in enumerate(col_nammes):\n",
        "  roc_value_y_validation=metrics.roc_auc_score(y_val[:,i],predict_y_val5[:,i])\n",
        "  roc_value_y_test=metrics.roc_auc_score(y_test[col],predict_y_test5[:,i])\n",
        "\n",
        "  print(col,\"Validation_accuracy:\",roc_value_y_validation,\"\\t Test Accuracy:\",roc_value_y_test,\"\\n\")\n",
        "\n",
        "  y_validation_val.append(roc_value_y_validation)\n",
        "  y_test_val.append(roc_value_y_test)\n",
        "  \n",
        "Accuracy_y_validation=statistics.mean(y_validation_val)\n",
        "Accuracy_y_test=statistics.mean(y_test_val)\n",
        "print(\"Accuracy_y_validation\",Accuracy_y_validation)\n",
        "print(\"Accuracy_y_test\",Accuracy_y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic Validation_accuracy: 0.76818389436878 \t Test Accuracy: 0.5848589417169636 \n",
            "\n",
            "severe_toxic Validation_accuracy: 0.8688742065756206 \t Test Accuracy: 0.548864111090473 \n",
            "\n",
            "obscene Validation_accuracy: 0.8226728522592465 \t Test Accuracy: 0.5741719368407189 \n",
            "\n",
            "threat Validation_accuracy: 0.804092787628316 \t Test Accuracy: 0.5473882939332189 \n",
            "\n",
            "insult Validation_accuracy: 0.8190379154342197 \t Test Accuracy: 0.5721308221204009 \n",
            "\n",
            "identity_hate Validation_accuracy: 0.7904996463056887 \t Test Accuracy: 0.5493289285780203 \n",
            "\n",
            "Accuracy_y_validation 0.8122268837619786\n",
            "Accuracy_y_test 0.5627905057132992\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}